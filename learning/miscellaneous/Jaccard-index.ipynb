{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb3fc9f",
   "metadata": {},
   "source": "# üìä √çndice de Jaccard: Medici√≥n de Similitud entre Conjuntos\n\nEste notebook explora el **√çndice de Jaccard**, una m√©trica fundamental en an√°lisis de datos para cuantificar la similitud entre conjuntos."
  },
  {
   "cell_type": "markdown",
   "id": "9bac0372",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": "## üéØ ¬øQu√© es el √çndice de Jaccard?\n\nEl **√çndice de Jaccard** ($I_J$), tambi√©n conocido como **Coeficiente de Jaccard**, es una m√©trica estad√≠stica utilizada para medir el grado de similitud entre dos conjuntos finitos, independientemente del tipo de elementos que contengan.\n\n### üìê Formulaci√≥n Matem√°tica\n\n$$\nJ(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}\n$$\n\nDonde:\n- $|A \\cap B|$ representa la cardinalidad de la **intersecci√≥n** de ambos conjuntos (elementos comunes)\n- $|A \\cup B|$ representa la cardinalidad de la **uni√≥n** de ambos conjuntos (elementos totales √∫nicos)\n\n### üìà Propiedades\n\n- **Rango**: El √≠ndice siempre toma valores entre **0** y **1**\n  - $J = 0$: Los conjuntos son completamente disjuntos (sin elementos en com√∫n)\n  - $J = 1$: Los conjuntos son id√©nticos (igualdad total)\n- **Simetr√≠a**: $J(A, B) = J(B, A)$\n- **Interpretaci√≥n**: A mayor valor, mayor similitud entre los conjuntos"
  },
  {
   "cell_type": "markdown",
   "id": "34cdd028",
   "metadata": {},
   "source": "---\n\n## üí° Caso de Uso 1: Detecci√≥n de Clusters Duplicados\n\nEn este ejemplo pr√°ctico, utilizamos el √≠ndice de Jaccard para identificar clusters de mensajes que son pr√°cticamente duplicados, bas√°ndonos en sus palabras clave (*keywords*). Esta t√©cnica es especialmente √∫til en:\n\n- **An√°lisis de redes sociales**: Agrupar conversaciones similares\n- **Sistemas de recomendaci√≥n**: Evitar contenido redundante\n- **Procesamiento de texto**: Deduplicaci√≥n de documentos"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faf3b038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters originales:\n",
      "0: {'model', 'data', 'training', 'ai'}\n",
      "1: {'learning', 'network', 'neural', 'deep'}\n",
      "2: {'model', 'dataset', 'training', 'ai'}\n",
      "3: {'meeting', 'break', 'coffee'}\n",
      "4: {'learning', 'network', 'neural', 'deep'}\n",
      "\n",
      "Posibles duplicados (√≠ndice1, √≠ndice2, similitud):\n",
      "(1, 4, 1.0)\n",
      "\n",
      "Clusters despu√©s de eliminar duplicados:\n",
      "{'model', 'data', 'training', 'ai'}\n",
      "{'learning', 'network', 'neural', 'deep'}\n",
      "{'model', 'dataset', 'training', 'ai'}\n",
      "{'meeting', 'break', 'coffee'}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo: Uso del √≠ndice de Jaccard para detectar clusters duplicados\n",
    "# ===============================================================\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"\n",
    "    Calcula la similitud de Jaccard entre dos conjuntos.\n",
    "    \"\"\"\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "\n",
    "# Supongamos que tenemos clusters de mensajes representados por keywords\n",
    "clusters = [\n",
    "    {\"ai\", \"model\", \"training\", \"data\"},\n",
    "    {\"deep\", \"learning\", \"neural\", \"network\"},\n",
    "    {\"ai\", \"model\", \"training\", \"dataset\"},\n",
    "    {\"coffee\", \"break\", \"meeting\"},\n",
    "    {\"neural\", \"network\", \"deep\", \"learning\"},\n",
    "]\n",
    "\n",
    "# Umbral de similitud para considerar duplicados\n",
    "threshold = 0.7\n",
    "\n",
    "# Detectar duplicados\n",
    "duplicates = []\n",
    "visited = set()\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    for j in range(i+1, len(clusters)):\n",
    "        sim = jaccard_similarity(clusters[i], clusters[j])\n",
    "        if sim >= threshold:\n",
    "            duplicates.append((i, j, sim))\n",
    "            visited.add(j)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Clusters originales:\")\n",
    "for idx, c in enumerate(clusters):\n",
    "    print(f\"{idx}: {c}\")\n",
    "\n",
    "print(\"\\nPosibles duplicados (√≠ndice1, √≠ndice2, similitud):\")\n",
    "for dup in duplicates:\n",
    "    print(dup)\n",
    "\n",
    "# Filtrar clusters √∫nicos\n",
    "unique_clusters = [c for idx, c in enumerate(clusters) if idx not in visited]\n",
    "\n",
    "print(\"\\nClusters despu√©s de eliminar duplicados:\")\n",
    "for c in unique_clusters:\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba81197",
   "metadata": {},
   "source": "---\n\n## üõí Caso de Uso 2: Sistemas de Recomendaci√≥n de Productos\n\nEn este ejemplo, aplicamos el √≠ndice de Jaccard para construir un **motor de recomendaci√≥n colaborativo** basado en el historial de compras de usuarios. \n\n### üéØ Objetivo\n\nMedir la similitud entre usuarios seg√∫n sus productos adquiridos para:\n- Recomendar productos que compraron usuarios similares\n- Identificar patrones de compra\n- Personalizar la experiencia de compra\n\n### üîç Metodolog√≠a\n\nComparamos los conjuntos de productos de diferentes usuarios y utilizamos el √≠ndice de Jaccard como m√©trica de similitud para determinar qu√© usuarios tienen preferencias similares."
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d24f82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud entre Usuario A y Usuario B: 0.4\n",
      "Similitud entre Usuario A y Usuario C: 0.0\n",
      "\n",
      "Usuario A y B son m√°s similares ‚Üí recomendar productos de B a A\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"\n",
    "    Calcula la similitud de Jaccard entre dos conjuntos.\n",
    "    \"\"\"\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "\n",
    "# Historial de compras de usuarios\n",
    "user_A = {\"laptop\", \"mouse\", \"keyboard\", \"monitor\"}\n",
    "user_B = {\"laptop\", \"mouse\", \"tablet\"}\n",
    "user_C = {\"shoes\", \"t-shirt\", \"jeans\"}\n",
    "\n",
    "# Calcular similitud\n",
    "sim_A_B = jaccard_similarity(user_A, user_B)\n",
    "sim_A_C = jaccard_similarity(user_A, user_C)\n",
    "\n",
    "print(\"Similitud entre Usuario A y Usuario B:\", sim_A_B)\n",
    "print(\"Similitud entre Usuario A y Usuario C:\", sim_A_C)\n",
    "\n",
    "# Decidir recomendaciones\n",
    "if sim_A_B > sim_A_C:\n",
    "    print(\"\\nUsuario A y B son m√°s similares ‚Üí recomendar productos de B a A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2891e",
   "metadata": {},
   "outputs": [],
   "source": "# üîç Caso de Uso 3: Detecci√≥n de Preguntas Similares mediante Tokenizaci√≥n\n# ============================================================================\n# Este an√°lisis identifica preguntas redundantes en un conjunto de preguntas\n# para eventos, utilizando tokenizaci√≥n simple (divisi√≥n por palabras).\n\ndef jaccard_similarity(set1, set2):\n    \"\"\"\n    Calcula la similitud de Jaccard entre dos conjuntos de palabras.\n    \"\"\"\n    intersection = len(set1.intersection(set2))\n    union = len(set1.union(set2))\n    return intersection / union if union != 0 else 0\n\n\n# Preguntas para un evento sobre ciencia de datos y experiencias personales\nquestions = [\n    \"¬øCu√°l ha sido tu mayor reto aprendiendo ciencia de datos?\",\n    \"¬øCu√°l ha sido tu mayor reto personal aprendiendo ciencia de datos avanzado?\",\n    \"¬øPuedes compartir una experiencia personal aplicando ciencia de datos en tu trabajo?\",\n    \"¬øCu√°l consideras la habilidad m√°s importante para un cient√≠fico de datos?\",\n    \"¬øQu√© consejo le dar√≠as a alguien que empieza en ciencia de datos?\",\n    \"¬øC√≥mo enfrentaste dificultades en proyectos de ciencia de datos pasados?\",\n    \"¬øQu√© frameworks prefieres para machine learning y por qu√©?\",\n    \"¬øCu√°l ha sido tu experiencia m√°s significativa aplicando modelos predictivos?\",\n    \"¬øQu√© aprendiste de tus primeros proyectos en ciencia de datos?\",\n    \"¬øC√≥mo manejas los errores y aprendizajes en proyectos de ciencia de datos?\"\n]\n\n# Convertimos cada pregunta en un conjunto de palabras (tokens)\n# Eliminamos signos de interrogaci√≥n para el an√°lisis\nquestion_sets = [set(q.lower().replace(\"¬ø\",\"\").replace(\"?\",\"\").split()) for q in questions]\n\n# Umbral de similitud: solo consideramos pares con similitud >= 0.8\nthreshold = 0.8\n\n# Comparar todas las preguntas entre s√≠\nsimilar_pairs = []\nfor i in range(len(question_sets)):\n    for j in range(i+1, len(question_sets)):\n        sim = jaccard_similarity(question_sets[i], question_sets[j])\n        if sim >= threshold:\n            similar_pairs.append(((questions[i], questions[j]), sim))\n\n# Mostrar resultados ordenados por similitud (descendente)\nprint(\"üîé Pares de preguntas similares (threshold =\", threshold, \"):\\n\")\nfor pair, sim in sorted(similar_pairs, key=lambda x: x[1], reverse=True):\n    print(f\"- [{sim:.2f}] '{pair[0]}'\\n          vs\\n          '{pair[1]}'\\n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1375400",
   "metadata": {},
   "outputs": [],
   "source": "# üß† Mejora mediante Lematizaci√≥n con SpaCy\n# ==========================================\n# En este enfoque avanzado, utilizamos lematizaci√≥n para normalizar las palabras\n# (ej: \"aprendiendo\" ‚Üí \"aprender\", \"datos\" ‚Üí \"dato\"), eliminando variaciones\n# morfol√≥gicas y mejorando la detecci√≥n de similitud sem√°ntica.\n\nimport spacy\n\n# Cargar modelo de lenguaje en espa√±ol\nnlp = spacy.load(\"es_core_news_sm\")\n\ndef lemmatize_text(text):\n    \"\"\"\n    Recibe un string y devuelve un conjunto de lemas (lemmas).\n    Elimina stopwords y signos de puntuaci√≥n para optimizar el an√°lisis.\n    \"\"\"\n    doc = nlp(text.lower().replace(\"¬ø\",\"\").replace(\"?\",\"\"))\n    return {token.lemma_ for token in doc if not token.is_punct and not token.is_stop}\n\n# Funci√≥n Jaccard\ndef jaccard_similarity(set1, set2):\n    intersection = len(set1.intersection(set2))\n    union = len(set1.union(set2))\n    return intersection / union if union != 0 else 0\n\n\n# üîπ 20 preguntas (10 originales + 10 nuevas variantes)\nquestions = [\n    # === Preguntas originales ===\n    \"¬øCu√°l ha sido tu mayor reto aprendiendo ciencia de datos?\",\n    \"¬øCu√°l ha sido tu mayor reto personal aprendiendo ciencia de datos avanzado?\",\n    \"¬øPuedes compartir una experiencia personal aplicando ciencia de datos en tu trabajo?\",\n    \"¬øCu√°l consideras la habilidad m√°s importante para un cient√≠fico de datos?\",\n    \"¬øQu√© consejo le dar√≠as a alguien que empieza en ciencia de datos?\",\n    \"¬øC√≥mo enfrentaste dificultades en proyectos de ciencia de datos pasados?\",\n    \"¬øQu√© frameworks prefieres para machine learning y por qu√©?\",\n    \"¬øCu√°l ha sido tu experiencia m√°s significativa aplicando modelos predictivos?\",\n    \"¬øQu√© aprendiste de tus primeros proyectos en ciencia de datos?\",\n    \"¬øC√≥mo manejas los errores y aprendizajes en proyectos de ciencia de datos?\",\n\n    # === Nuevas variantes (algunas muy similares, otras distintas) ===\n    \"¬øCu√°l fue tu mayor reto cuando comenzaste a estudiar ciencia de datos?\",\n    \"¬øPuedes contar una experiencia positiva aplicando ciencia de datos en un proyecto?\",\n    \"¬øQu√© habilidades blandas consideras necesarias para trabajar en ciencia de datos?\",\n    \"¬øQu√© opinas sobre la importancia de la √©tica en proyectos de inteligencia artificial?\",\n    \"¬øCu√°l ha sido la herramienta m√°s √∫til para ti en proyectos de machine learning?\",\n    \"¬øQu√© recomendar√≠as a alguien que quiere especializarse en big data?\",\n    \"¬øC√≥mo describir√≠as tu curva de aprendizaje en ciencia de datos?\",\n    \"¬øQu√© importancia le das al trabajo en equipo en proyectos de ciencia de datos?\",\n    \"¬øCu√°l es tu framework favorito para deep learning y por qu√©?\",\n    \"¬øQu√© retos ves en el futuro de la ciencia de datos en Am√©rica Latina?\"\n]\n\n\n# Convertimos cada pregunta a conjunto de lemas\nquestion_sets = [lemmatize_text(q) for q in questions]\n\n# Umbral de similitud reducido a 0.5 para captar m√°s variaciones\nthreshold = 0.5\n\n# Comparar todas las preguntas\nsimilar_pairs = []\nfor i in range(len(question_sets)):\n    for j in range(i+1, len(question_sets)):\n        sim = jaccard_similarity(question_sets[i], question_sets[j])\n        if sim >= threshold:\n            similar_pairs.append(((questions[i], questions[j]), sim))\n\n# Mostrar resultados ordenados por similitud\nprint(\"üîé Pares de preguntas similares con lematizaci√≥n (threshold =\", threshold, \"):\\n\")\nfor pair, sim in sorted(similar_pairs, key=lambda x: x[1], reverse=True):\n    print(f\"- [{sim:.2f}] '{pair[0]}'\\n          vs\\n          '{pair[1]}'\\n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3519f6a",
   "metadata": {},
   "outputs": [],
   "source": "# üéØ Clustering Autom√°tico de Preguntas Similares\n# ================================================\n# Este algoritmo agrupa preguntas similares en clusters utilizando el √≠ndice de Jaccard\n# con lematizaci√≥n. Es √∫til para organizar preguntas en categor√≠as tem√°ticas autom√°ticamente.\n\nimport spacy\n\n# Cargar modelo en espa√±ol\nnlp = spacy.load(\"es_core_news_sm\")\n\ndef lemmatize_text(text):\n    \"\"\"\n    Recibe un string y devuelve un conjunto de lemas (lemmas).\n    \"\"\"\n    doc = nlp(text.lower().replace(\"¬ø\",\"\").replace(\"?\",\"\"))\n    return {token.lemma_ for token in doc if not token.is_punct and not token.is_stop}\n\n# Funci√≥n Jaccard\ndef jaccard_similarity(set1, set2):\n    intersection = len(set1.intersection(set2))\n    union = len(set1.union(set2))\n    return intersection / union if union != 0 else 0\n\n# üìã Dataset ampliado: Preguntas generales + temporales\nquestions = [\n    # === Preguntas sobre experiencia y aprendizaje ===\n    \"¬øCu√°l ha sido tu mayor reto aprendiendo ciencia de datos?\",\n    \"¬øCu√°l ha sido tu mayor reto personal aprendiendo ciencia de datos avanzado?\",\n    \"¬øPuedes compartir una experiencia personal aplicando ciencia de datos en tu trabajo?\",\n    \"¬øCu√°l consideras la habilidad m√°s importante para un cient√≠fico de datos?\",\n    \"¬øQu√© consejo le dar√≠as a alguien que empieza en ciencia de datos?\",\n    \"¬øC√≥mo enfrentaste dificultades en proyectos de ciencia de datos pasados?\",\n    \"¬øQu√© frameworks prefieres para machine learning y por qu√©?\",\n    \"¬øCu√°l ha sido tu experiencia m√°s significativa aplicando modelos predictivos?\",\n    \"¬øQu√© aprendiste de tus primeros proyectos en ciencia de datos?\",\n    \"¬øC√≥mo manejas los errores y aprendizajes en proyectos de ciencia de datos?\",\n    \"¬øCu√°l fue tu mayor reto cuando comenzaste a estudiar ciencia de datos?\",\n    \"¬øPuedes contar una experiencia positiva aplicando ciencia de datos en un proyecto?\",\n    \"¬øQu√© habilidades blandas consideras necesarias para trabajar en ciencia de datos?\",\n    \"¬øQu√© opinas sobre la importancia de la √©tica en proyectos de inteligencia artificial?\",\n    \"¬øCu√°l ha sido la herramienta m√°s √∫til para ti en proyectos de machine learning?\",\n    \"¬øQu√© recomendar√≠as a alguien que quiere especializarse en big data?\",\n    \"¬øC√≥mo describir√≠as tu curva de aprendizaje en ciencia de datos?\",\n    \"¬øQu√© importancia le das al trabajo en equipo en proyectos de ciencia de datos?\",\n    \"¬øCu√°l es tu framework favorito para deep learning y por qu√©?\",\n    \"¬øQu√© retos ves en el futuro de la ciencia de datos en Am√©rica Latina?\",\n    \n    # === Preguntas sobre trayectoria temporal ===\n    \"¬øA qu√© edad empezaste a estudiar ciencia de datos?\",\n    \"¬øCu√°ntos a√±os llevas aprendiendo ciencia de datos?\",\n    \"¬øHace cu√°nto tiempo comenzaste a interesarte en ciencia de datos?\",\n    \"¬øCu√°nto tiempo te tom√≥ aprender los fundamentos de ciencia de datos?\",\n    \"¬øEn qu√© a√±o iniciaste tu carrera en ciencia de datos?\",\n    \"¬øCu√°nto tiempo dedicas semanalmente a proyectos de ciencia de datos?\",\n    \"¬øC√≥mo ha evolucionado tu aprendizaje de ciencia de datos a lo largo de los a√±os?\",\n    \"¬øCu√°ntos proyectos personales has hecho desde que comenzaste en ciencia de datos?\",\n    \"¬øCu√°nto tiempo llevas aplicando ciencia de datos en el trabajo?\",\n    \"¬øHace cu√°ntos a√±os escuchaste por primera vez sobre ciencia de datos?\"\n]\n\n# Convertimos cada pregunta a conjunto de lemas\nquestion_sets = [lemmatize_text(q) for q in questions]\n\n# Umbral de similitud para clustering\nthreshold = 0.65\n\n# üîπ Algoritmo de clustering simple basado en similitud Jaccard\nclusters = []\nused = set()\n\nfor i in range(len(questions)):\n    if i in used:\n        continue\n    cluster = [(questions[i], question_sets[i])]\n    used.add(i)\n    for j in range(i+1, len(questions)):\n        sim = jaccard_similarity(question_sets[i], question_sets[j])\n        if sim >= threshold:\n            cluster.append((questions[j], question_sets[j]))\n            used.add(j)\n    clusters.append(cluster)\n\n# üìä Mostrar clusters con formato mejorado\nprint(f\"üéØ Clusters de preguntas similares (threshold = {threshold}):\\n\")\nprint(\"=\" * 80 + \"\\n\")\n\nfor idx, cluster in enumerate(clusters, 1):\n    print(f\"üîπ **Grupo {idx}** ({len(cluster)} pregunta{'s' if len(cluster) > 1 else ''}):\")\n    for q, lemmas in cluster:\n        print(f\"   üìå {q}\")\n        print(f\"      üî§ Lemmas: {lemmas}\")\n    print(\"\\n\" + \"-\" * 80 + \"\\n\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "c1252e56",
   "metadata": {},
   "outputs": [],
   "source": "---\n\n## üéì Conclusiones\n\nEl **√çndice de Jaccard** es una herramienta poderosa y vers√°til para medir similitud en diversos contextos:\n\n### ‚úÖ Ventajas\n- **Simplicidad**: F√°cil de implementar y comprender\n- **Versatilidad**: Aplicable a cualquier tipo de conjunto (texto, productos, usuarios, etc.)\n- **Interpretabilidad**: Valor normalizado entre 0 y 1, f√°cil de interpretar\n\n### ‚ö†Ô∏è Limitaciones\n- **Sensibilidad al tama√±o**: No considera la frecuencia de elementos\n- **Tokenizaci√≥n b√°sica**: Requiere t√©cnicas adicionales (lematizaci√≥n, embeddings) para mejores resultados en texto\n- **Contexto sem√°ntico**: No captura relaciones sem√°nticas profundas (sin√≥nimos, polisemia)\n\n### üöÄ Aplicaciones Pr√°cticas\n1. **Sistemas de recomendaci√≥n**: Usuarios o productos similares\n2. **Deduplicaci√≥n**: Detectar contenido redundante\n3. **An√°lisis de clustering**: Agrupar elementos similares\n4. **Recuperaci√≥n de informaci√≥n**: B√∫squeda de documentos similares\n5. **NLP**: Comparaci√≥n de textos, an√°lisis de similitud de preguntas\n\n---\n\nüìö **Referencias adicionales**:\n- [Wikipedia: Jaccard Index](https://en.wikipedia.org/wiki/Jaccard_index)\n- [SpaCy: Lematizaci√≥n en espa√±ol](https://spacy.io/models/es)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PySpark)",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}