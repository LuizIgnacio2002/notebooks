{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb3fc9f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bac0372",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "El **Ã­ndice de Jaccard** ($I_J$) o **coeficiente de Jaccard** ($I_J$) mide el grado de similitud entre dos conjuntos, sea cual sea el tipo de elementos.\n",
    "\n",
    "La formulaciÃ³n es la siguiente:\n",
    "\n",
    "$$\n",
    "J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}\n",
    "$$\n",
    "\n",
    "Es decir, la cardinalidad de la intersecciÃ³n de ambos conjuntos dividida por la cardinalidad de su uniÃ³n.\n",
    "\n",
    "Siempre toma valores entre $0$ y $1$, correspondiendo este Ãºltimo a la igualdad total entre ambos conjuntos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cdd028",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faf3b038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters originales:\n",
      "0: {'model', 'data', 'training', 'ai'}\n",
      "1: {'learning', 'network', 'neural', 'deep'}\n",
      "2: {'model', 'dataset', 'training', 'ai'}\n",
      "3: {'meeting', 'break', 'coffee'}\n",
      "4: {'learning', 'network', 'neural', 'deep'}\n",
      "\n",
      "Posibles duplicados (Ã­ndice1, Ã­ndice2, similitud):\n",
      "(1, 4, 1.0)\n",
      "\n",
      "Clusters despuÃ©s de eliminar duplicados:\n",
      "{'model', 'data', 'training', 'ai'}\n",
      "{'learning', 'network', 'neural', 'deep'}\n",
      "{'model', 'dataset', 'training', 'ai'}\n",
      "{'meeting', 'break', 'coffee'}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo: Uso del Ã­ndice de Jaccard para detectar clusters duplicados\n",
    "# ===============================================================\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"\n",
    "    Calcula la similitud de Jaccard entre dos conjuntos.\n",
    "    \"\"\"\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "\n",
    "# Supongamos que tenemos clusters de mensajes representados por keywords\n",
    "clusters = [\n",
    "    {\"ai\", \"model\", \"training\", \"data\"},\n",
    "    {\"deep\", \"learning\", \"neural\", \"network\"},\n",
    "    {\"ai\", \"model\", \"training\", \"dataset\"},\n",
    "    {\"coffee\", \"break\", \"meeting\"},\n",
    "    {\"neural\", \"network\", \"deep\", \"learning\"},\n",
    "]\n",
    "\n",
    "# Umbral de similitud para considerar duplicados\n",
    "threshold = 0.7\n",
    "\n",
    "# Detectar duplicados\n",
    "duplicates = []\n",
    "visited = set()\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    for j in range(i+1, len(clusters)):\n",
    "        sim = jaccard_similarity(clusters[i], clusters[j])\n",
    "        if sim >= threshold:\n",
    "            duplicates.append((i, j, sim))\n",
    "            visited.add(j)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Clusters originales:\")\n",
    "for idx, c in enumerate(clusters):\n",
    "    print(f\"{idx}: {c}\")\n",
    "\n",
    "print(\"\\nPosibles duplicados (Ã­ndice1, Ã­ndice2, similitud):\")\n",
    "for dup in duplicates:\n",
    "    print(dup)\n",
    "\n",
    "# Filtrar clusters Ãºnicos\n",
    "unique_clusters = [c for idx, c in enumerate(clusters) if idx not in visited]\n",
    "\n",
    "print(\"\\nClusters despuÃ©s de eliminar duplicados:\")\n",
    "for c in unique_clusters:\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba81197",
   "metadata": {},
   "source": [
    "Caso: RecomendaciÃ³n de productos\n",
    "Supongamos que tenemos dos usuarios y cada uno tiene un conjunto de productos comprados. Queremos medir quÃ© tan similares son dos usuarios segÃºn sus compras, para usarlos en un sistema de recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d24f82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud entre Usuario A y Usuario B: 0.4\n",
      "Similitud entre Usuario A y Usuario C: 0.0\n",
      "\n",
      "Usuario A y B son mÃ¡s similares â†’ recomendar productos de B a A\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"\n",
    "    Calcula la similitud de Jaccard entre dos conjuntos.\n",
    "    \"\"\"\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "\n",
    "# Historial de compras de usuarios\n",
    "user_A = {\"laptop\", \"mouse\", \"keyboard\", \"monitor\"}\n",
    "user_B = {\"laptop\", \"mouse\", \"tablet\"}\n",
    "user_C = {\"shoes\", \"t-shirt\", \"jeans\"}\n",
    "\n",
    "# Calcular similitud\n",
    "sim_A_B = jaccard_similarity(user_A, user_B)\n",
    "sim_A_C = jaccard_similarity(user_A, user_C)\n",
    "\n",
    "print(\"Similitud entre Usuario A y Usuario B:\", sim_A_B)\n",
    "print(\"Similitud entre Usuario A y Usuario C:\", sim_A_C)\n",
    "\n",
    "# Decidir recomendaciones\n",
    "if sim_A_B > sim_A_C:\n",
    "    print(\"\\nUsuario A y B son mÃ¡s similares â†’ recomendar productos de B a A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90e2891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pares de preguntas similares (threshold = 0.8 ):\n",
      "\n",
      "- [0.83] 'Â¿CuÃ¡l ha sido tu mayor reto aprendiendo ciencia de datos?'\n",
      "          vs\n",
      "          'Â¿CuÃ¡l ha sido tu mayor reto personal aprendiendo ciencia de datos avanzado?'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"\n",
    "    Calcula la similitud de Jaccard entre dos conjuntos de palabras.\n",
    "    \"\"\"\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "\n",
    "# Preguntas para un evento sobre ciencia de datos y experiencias personales\n",
    "questions = [\n",
    "    \"Â¿CuÃ¡l ha sido tu mayor reto aprendiendo ciencia de datos?\",\n",
    "    \"Â¿CuÃ¡l ha sido tu mayor reto personal aprendiendo ciencia de datos avanzado?\",\n",
    "    \"Â¿Puedes compartir una experiencia personal aplicando ciencia de datos en tu trabajo?\",\n",
    "    \"Â¿CuÃ¡l consideras la habilidad mÃ¡s importante para un cientÃ­fico de datos?\",\n",
    "    \"Â¿QuÃ© consejo le darÃ­as a alguien que empieza en ciencia de datos?\",\n",
    "    \"Â¿CÃ³mo enfrentaste dificultades en proyectos de ciencia de datos pasados?\",\n",
    "    \"Â¿QuÃ© frameworks prefieres para machine learning y por quÃ©?\",\n",
    "    \"Â¿CuÃ¡l ha sido tu experiencia mÃ¡s significativa aplicando modelos predictivos?\",\n",
    "    \"Â¿QuÃ© aprendiste de tus primeros proyectos en ciencia de datos?\",\n",
    "    \"Â¿CÃ³mo manejas los errores y aprendizajes en proyectos de ciencia de datos?\"\n",
    "]\n",
    "\n",
    "# Convertimos cada pregunta en un conjunto de palabras (tokens)\n",
    "question_sets = [set(q.lower().replace(\"Â¿\",\"\").replace(\"?\",\"\").split()) for q in questions]\n",
    "\n",
    "# Threshold de similitud\n",
    "threshold = 0.8\n",
    "\n",
    "# Comparar todas las preguntas entre sÃ­\n",
    "similar_pairs = []\n",
    "for i in range(len(question_sets)):\n",
    "    for j in range(i+1, len(question_sets)):\n",
    "        sim = jaccard_similarity(question_sets[i], question_sets[j])\n",
    "        if sim >= threshold:\n",
    "            similar_pairs.append(((questions[i], questions[j]), sim))\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Pares de preguntas similares (threshold =\", threshold, \"):\\n\")\n",
    "for pair, sim in sorted(similar_pairs, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"- [{sim:.2f}] '{pair[0]}'\\n          vs\\n          '{pair[1]}'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1375400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pares de preguntas similares (threshold = 0.5 ):\n",
      "\n",
      "- [0.67] 'Â¿CuÃ¡l ha sido tu mayor reto aprendiendo ciencia de datos?'\n",
      "          vs\n",
      "          'Â¿CuÃ¡l ha sido tu mayor reto personal aprendiendo ciencia de datos avanzado?'\n",
      "\n",
      "- [0.50] 'Â¿CuÃ¡l ha sido tu mayor reto aprendiendo ciencia de datos?'\n",
      "          vs\n",
      "          'Â¿CuÃ¡l fue tu mayor reto cuando comenzaste a estudiar ciencia de datos?'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargar modelo en espaÃ±ol\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Recibe un string y devuelve un conjunto de lemas (lemmas).\n",
    "    \"\"\"\n",
    "    doc = nlp(text.lower().replace(\"Â¿\",\"\").replace(\"?\",\"\"))\n",
    "    return {token.lemma_ for token in doc if not token.is_punct and not token.is_stop}\n",
    "\n",
    "# FunciÃ³n Jaccard\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "\n",
    "# Preguntas\n",
    "# ðŸ”¹ 20 preguntas (10 originales + 10 nuevas)\n",
    "questions = [\n",
    "    # Originales\n",
    "    \"Â¿CuÃ¡l ha sido tu mayor reto aprendiendo ciencia de datos?\",\n",
    "    \"Â¿CuÃ¡l ha sido tu mayor reto personal aprendiendo ciencia de datos avanzado?\",\n",
    "    \"Â¿Puedes compartir una experiencia personal aplicando ciencia de datos en tu trabajo?\",\n",
    "    \"Â¿CuÃ¡l consideras la habilidad mÃ¡s importante para un cientÃ­fico de datos?\",\n",
    "    \"Â¿QuÃ© consejo le darÃ­as a alguien que empieza en ciencia de datos?\",\n",
    "    \"Â¿CÃ³mo enfrentaste dificultades en proyectos de ciencia de datos pasados?\",\n",
    "    \"Â¿QuÃ© frameworks prefieres para machine learning y por quÃ©?\",\n",
    "    \"Â¿CuÃ¡l ha sido tu experiencia mÃ¡s significativa aplicando modelos predictivos?\",\n",
    "    \"Â¿QuÃ© aprendiste de tus primeros proyectos en ciencia de datos?\",\n",
    "    \"Â¿CÃ³mo manejas los errores y aprendizajes en proyectos de ciencia de datos?\",\n",
    "\n",
    "    # Nuevas (algunas muy similares y otras distintas)\n",
    "    \"Â¿CuÃ¡l fue tu mayor reto cuando comenzaste a estudiar ciencia de datos?\",\n",
    "    \"Â¿Puedes contar una experiencia positiva aplicando ciencia de datos en un proyecto?\",\n",
    "    \"Â¿QuÃ© habilidades blandas consideras necesarias para trabajar en ciencia de datos?\",\n",
    "    \"Â¿QuÃ© opinas sobre la importancia de la Ã©tica en proyectos de inteligencia artificial?\",\n",
    "    \"Â¿CuÃ¡l ha sido la herramienta mÃ¡s Ãºtil para ti en proyectos de machine learning?\",\n",
    "    \"Â¿QuÃ© recomendarÃ­as a alguien que quiere especializarse en big data?\",\n",
    "    \"Â¿CÃ³mo describirÃ­as tu curva de aprendizaje en ciencia de datos?\",\n",
    "    \"Â¿QuÃ© importancia le das al trabajo en equipo en proyectos de ciencia de datos?\",\n",
    "    \"Â¿CuÃ¡l es tu framework favorito para deep learning y por quÃ©?\",\n",
    "    \"Â¿QuÃ© retos ves en el futuro de la ciencia de datos en AmÃ©rica Latina?\"\n",
    "]\n",
    "\n",
    "\n",
    "# Convertimos cada pregunta a conjunto de lemas\n",
    "question_sets = [lemmatize_text(q) for q in questions]\n",
    "\n",
    "# Threshold de similitud\n",
    "threshold = 0.5\n",
    "\n",
    "# Comparar todas las preguntas\n",
    "similar_pairs = []\n",
    "for i in range(len(question_sets)):\n",
    "    for j in range(i+1, len(question_sets)):\n",
    "        sim = jaccard_similarity(question_sets[i], question_sets[j])\n",
    "        if sim >= threshold:\n",
    "            similar_pairs.append(((questions[i], questions[j]), sim))\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Pares de preguntas similares (threshold =\", threshold, \"):\\n\")\n",
    "for pair, sim in sorted(similar_pairs, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"- [{sim:.2f}] '{pair[0]}'\\n          vs\\n          '{pair[1]}'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3519f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters de preguntas similares (threshold = 0.65 ):\n",
      "\n",
      "ðŸ”¹ Grupo 1:\n",
      "   - Â¿CuÃ¡l ha sido tu mayor reto aprendiendo ciencia de datos?\n",
      "      Lemmas: {'aprender', 'reto', 'dato', 'ciencia'}\n",
      "   - Â¿CuÃ¡l ha sido tu mayor reto personal aprendiendo ciencia de datos avanzado?\n",
      "      Lemmas: {'aprender', 'personal', 'avanzado', 'reto', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 2:\n",
      "   - Â¿Puedes compartir una experiencia personal aplicando ciencia de datos en tu trabajo?\n",
      "      Lemmas: {'dato', 'poder', 'personal', 'compartir', 'experiencia', 'aplicar', 'ciencia', 'trabajo'}\n",
      "\n",
      "ðŸ”¹ Grupo 3:\n",
      "   - Â¿CuÃ¡l consideras la habilidad mÃ¡s importante para un cientÃ­fico de datos?\n",
      "      Lemmas: {'considera', 'cientÃ­fico', 'habilidad', 'dato', 'importante'}\n",
      "\n",
      "ðŸ”¹ Grupo 4:\n",
      "   - Â¿QuÃ© consejo le darÃ­as a alguien que empieza en ciencia de datos?\n",
      "      Lemmas: {'dariar', 'consejo', 'alguien', 'empezar', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 5:\n",
      "   - Â¿CÃ³mo enfrentaste dificultades en proyectos de ciencia de datos pasados?\n",
      "      Lemmas: {'proyecto', 'pasado', 'enfrentastar', 'dificultad', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 6:\n",
      "   - Â¿QuÃ© frameworks prefieres para machine learning y por quÃ©?\n",
      "      Lemmas: {'frameworks', 'machine', 'prefier', 'learning'}\n",
      "\n",
      "ðŸ”¹ Grupo 7:\n",
      "   - Â¿CuÃ¡l ha sido tu experiencia mÃ¡s significativa aplicando modelos predictivos?\n",
      "      Lemmas: {'predictivo', 'modelo', 'experiencia', 'significativo', 'aplicar'}\n",
      "\n",
      "ðŸ”¹ Grupo 8:\n",
      "   - Â¿QuÃ© aprendiste de tus primeros proyectos en ciencia de datos?\n",
      "      Lemmas: {'proyecto', 'dato', 'ciencia', 'aprendiste'}\n",
      "\n",
      "ðŸ”¹ Grupo 9:\n",
      "   - Â¿CÃ³mo manejas los errores y aprendizajes en proyectos de ciencia de datos?\n",
      "      Lemmas: {'proyecto', 'error', 'aprendizaje', 'manejar', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 10:\n",
      "   - Â¿CuÃ¡l fue tu mayor reto cuando comenzaste a estudiar ciencia de datos?\n",
      "      Lemmas: {'comenzastar', 'estudiar', 'reto', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 11:\n",
      "   - Â¿Puedes contar una experiencia positiva aplicando ciencia de datos en un proyecto?\n",
      "      Lemmas: {'dato', 'proyecto', 'poder', 'positivo', 'contar', 'experiencia', 'aplicar', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 12:\n",
      "   - Â¿QuÃ© habilidades blandas consideras necesarias para trabajar en ciencia de datos?\n",
      "      Lemmas: {'considera', 'trabajar', 'necesario', 'blando', 'dato', 'ciencia', 'habilidad'}\n",
      "\n",
      "ðŸ”¹ Grupo 13:\n",
      "   - Â¿QuÃ© opinas sobre la importancia de la Ã©tica en proyectos de inteligencia artificial?\n",
      "      Lemmas: {'artificial', 'importancia', 'proyecto', 'Ã©tica', 'inteligencia', 'opina'}\n",
      "\n",
      "ðŸ”¹ Grupo 14:\n",
      "   - Â¿CuÃ¡l ha sido la herramienta mÃ¡s Ãºtil para ti en proyectos de machine learning?\n",
      "      Lemmas: {'proyecto', 'herramienta', 'machine', 'learning', 'Ãºtil'}\n",
      "\n",
      "ðŸ”¹ Grupo 15:\n",
      "   - Â¿QuÃ© recomendarÃ­as a alguien que quiere especializarse en big data?\n",
      "      Lemmas: {'big', 'especializar Ã©l', 'recomendarÃ­a', 'alguien', 'datar'}\n",
      "\n",
      "ðŸ”¹ Grupo 16:\n",
      "   - Â¿CÃ³mo describirÃ­as tu curva de aprendizaje en ciencia de datos?\n",
      "      Lemmas: {'describiriar', 'aprendizaje', 'curva', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 17:\n",
      "   - Â¿QuÃ© importancia le das al trabajo en equipo en proyectos de ciencia de datos?\n",
      "      Lemmas: {'importancia', 'proyecto', 'dar', 'equipo', 'dato', 'ciencia', 'trabajo'}\n",
      "\n",
      "ðŸ”¹ Grupo 18:\n",
      "   - Â¿CuÃ¡l es tu framework favorito para deep learning y por quÃ©?\n",
      "      Lemmas: {'deep', 'framework', 'favorito', 'learning'}\n",
      "\n",
      "ðŸ”¹ Grupo 19:\n",
      "   - Â¿QuÃ© retos ves en el futuro de la ciencia de datos en AmÃ©rica Latina?\n",
      "      Lemmas: {'latino', 'futuro', 'reto', 'ves', 'dato', 'ciencia', 'amÃ©rica'}\n",
      "\n",
      "ðŸ”¹ Grupo 20:\n",
      "   - Â¿A quÃ© edad empezaste a estudiar ciencia de datos?\n",
      "      Lemmas: {'empezastar', 'edad', 'estudiar', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 21:\n",
      "   - Â¿CuÃ¡ntos aÃ±os llevas aprendiendo ciencia de datos?\n",
      "      Lemmas: {'aprender', 'aÃ±o', 'lleva', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 22:\n",
      "   - Â¿Hace cuÃ¡nto tiempo comenzaste a interesarte en ciencia de datos?\n",
      "      Lemmas: {'comenzastar', 'interesarte', 'tiempo', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 23:\n",
      "   - Â¿CuÃ¡nto tiempo te tomÃ³ aprender los fundamentos de ciencia de datos?\n",
      "      Lemmas: {'aprender', 'tiempo', 'tomar', 'fundamento', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 24:\n",
      "   - Â¿En quÃ© aÃ±o iniciaste tu carrera en ciencia de datos?\n",
      "      Lemmas: {'aÃ±o', 'iniciastar', 'carrera', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 25:\n",
      "   - Â¿CuÃ¡nto tiempo dedicas semanalmente a proyectos de ciencia de datos?\n",
      "      Lemmas: {'dedica', 'proyecto', 'semanalmente', 'tiempo', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 26:\n",
      "   - Â¿CÃ³mo ha evolucionado tu aprendizaje de ciencia de datos a lo largo de los aÃ±os?\n",
      "      Lemmas: {'aÃ±o', 'aprendizaje', 'evolucionar', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 27:\n",
      "   - Â¿CuÃ¡ntos proyectos personales has hecho desde que comenzaste en ciencia de datos?\n",
      "      Lemmas: {'comenzastar', 'proyecto', 'personal', 'has', 'dato', 'ciencia'}\n",
      "\n",
      "ðŸ”¹ Grupo 28:\n",
      "   - Â¿CuÃ¡nto tiempo llevas aplicando ciencia de datos en el trabajo?\n",
      "      Lemmas: {'lleva', 'aplicar', 'tiempo', 'dato', 'ciencia', 'trabajo'}\n",
      "\n",
      "ðŸ”¹ Grupo 29:\n",
      "   - Â¿Hace cuÃ¡ntos aÃ±os escuchaste por primera vez sobre ciencia de datos?\n",
      "      Lemmas: {'dato', 'aÃ±o', 'ciencia', 'escuchastar'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargar modelo en espaÃ±ol\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Recibe un string y devuelve un conjunto de lemas (lemmas).\n",
    "    \"\"\"\n",
    "    doc = nlp(text.lower().replace(\"Â¿\",\"\").replace(\"?\",\"\"))\n",
    "    return {token.lemma_ for token in doc if not token.is_punct and not token.is_stop}\n",
    "\n",
    "# FunciÃ³n Jaccard\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# Preguntas (originales + personales)\n",
    "questions = [\n",
    "    \"Â¿CuÃ¡l ha sido tu mayor reto aprendiendo ciencia de datos?\",\n",
    "    \"Â¿CuÃ¡l ha sido tu mayor reto personal aprendiendo ciencia de datos avanzado?\",\n",
    "    \"Â¿Puedes compartir una experiencia personal aplicando ciencia de datos en tu trabajo?\",\n",
    "    \"Â¿CuÃ¡l consideras la habilidad mÃ¡s importante para un cientÃ­fico de datos?\",\n",
    "    \"Â¿QuÃ© consejo le darÃ­as a alguien que empieza en ciencia de datos?\",\n",
    "    \"Â¿CÃ³mo enfrentaste dificultades en proyectos de ciencia de datos pasados?\",\n",
    "    \"Â¿QuÃ© frameworks prefieres para machine learning y por quÃ©?\",\n",
    "    \"Â¿CuÃ¡l ha sido tu experiencia mÃ¡s significativa aplicando modelos predictivos?\",\n",
    "    \"Â¿QuÃ© aprendiste de tus primeros proyectos en ciencia de datos?\",\n",
    "    \"Â¿CÃ³mo manejas los errores y aprendizajes en proyectos de ciencia de datos?\",\n",
    "    \"Â¿CuÃ¡l fue tu mayor reto cuando comenzaste a estudiar ciencia de datos?\",\n",
    "    \"Â¿Puedes contar una experiencia positiva aplicando ciencia de datos en un proyecto?\",\n",
    "    \"Â¿QuÃ© habilidades blandas consideras necesarias para trabajar en ciencia de datos?\",\n",
    "    \"Â¿QuÃ© opinas sobre la importancia de la Ã©tica en proyectos de inteligencia artificial?\",\n",
    "    \"Â¿CuÃ¡l ha sido la herramienta mÃ¡s Ãºtil para ti en proyectos de machine learning?\",\n",
    "    \"Â¿QuÃ© recomendarÃ­as a alguien que quiere especializarse en big data?\",\n",
    "    \"Â¿CÃ³mo describirÃ­as tu curva de aprendizaje en ciencia de datos?\",\n",
    "    \"Â¿QuÃ© importancia le das al trabajo en equipo en proyectos de ciencia de datos?\",\n",
    "    \"Â¿CuÃ¡l es tu framework favorito para deep learning y por quÃ©?\",\n",
    "    \"Â¿QuÃ© retos ves en el futuro de la ciencia de datos en AmÃ©rica Latina?\",\n",
    "    \"Â¿A quÃ© edad empezaste a estudiar ciencia de datos?\",\n",
    "    \"Â¿CuÃ¡ntos aÃ±os llevas aprendiendo ciencia de datos?\",\n",
    "    \"Â¿Hace cuÃ¡nto tiempo comenzaste a interesarte en ciencia de datos?\",\n",
    "    \"Â¿CuÃ¡nto tiempo te tomÃ³ aprender los fundamentos de ciencia de datos?\",\n",
    "    \"Â¿En quÃ© aÃ±o iniciaste tu carrera en ciencia de datos?\",\n",
    "    \"Â¿CuÃ¡nto tiempo dedicas semanalmente a proyectos de ciencia de datos?\",\n",
    "    \"Â¿CÃ³mo ha evolucionado tu aprendizaje de ciencia de datos a lo largo de los aÃ±os?\",\n",
    "    \"Â¿CuÃ¡ntos proyectos personales has hecho desde que comenzaste en ciencia de datos?\",\n",
    "    \"Â¿CuÃ¡nto tiempo llevas aplicando ciencia de datos en el trabajo?\",\n",
    "    \"Â¿Hace cuÃ¡ntos aÃ±os escuchaste por primera vez sobre ciencia de datos?\"\n",
    "]\n",
    "\n",
    "# Convertimos cada pregunta a conjunto de lemas\n",
    "question_sets = [lemmatize_text(q) for q in questions]\n",
    "\n",
    "# Threshold\n",
    "threshold = 0.65\n",
    "\n",
    "# ðŸ”¹ Clustering simple basado en similitud Jaccard\n",
    "clusters = []\n",
    "used = set()\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    if i in used:\n",
    "        continue\n",
    "    cluster = [(questions[i], question_sets[i])]\n",
    "    used.add(i)\n",
    "    for j in range(i+1, len(questions)):\n",
    "        sim = jaccard_similarity(question_sets[i], question_sets[j])\n",
    "        if sim >= threshold:\n",
    "            cluster.append((questions[j], question_sets[j]))\n",
    "            used.add(j)\n",
    "    clusters.append(cluster)\n",
    "\n",
    "# Mostrar clusters\n",
    "print(\"Clusters de preguntas similares (threshold =\", threshold, \"):\\n\")\n",
    "for idx, cluster in enumerate(clusters, 1):\n",
    "    print(f\"ðŸ”¹ Grupo {idx}:\")\n",
    "    for q, lemmas in cluster:\n",
    "        print(\"   -\", q)\n",
    "        print(\"      Lemmas:\", lemmas)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1252e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
